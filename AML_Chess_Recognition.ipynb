{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 12:49:45.169876: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-06 12:49:46.897493: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from zipfile import ZipFile\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.feature import hog\n",
    "from skimage.io import imread\n",
    "from skimage import color, exposure\n",
    "from skimage.transform import rescale\n",
    "from skimage.util import view_as_blocks\n",
    "from multiprocessing import Pool\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import multiprocess as mp\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from multiprocessingNotebook import runt\n",
    "\n",
    "PICKLE_PATH = 'test_data.pickle'\n",
    "\n",
    "NUM_TRAINING_IMAGES = 500\n",
    "NUM_TESTING_IMAGES = 50\n",
    "\n",
    "NUM_SPACES_PER_BOARD = 2\n",
    "PICTURE_DIMENSIONS = 400\n",
    "block_width = PICTURE_DIMENSIONS // 8\n",
    "block_height = PICTURE_DIMENSIONS // 8\n",
    "num_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in test:  80000\n",
      "Files in train:  20000\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "def getFilePaths(filePath):\n",
    "    # opens the chess boards.zip file into the chessBoards object\n",
    "    chessBoards = ZipFile(filePath, 'r')\n",
    "\n",
    "    test = []\n",
    "    train = []\n",
    "\n",
    "    # extract the file names from the train and test folders in the zip archive\n",
    "    for file in chessBoards.namelist():\n",
    "        # fills the file names from within the dataset subfolder\n",
    "        if file[:4] == 'test':\n",
    "            test.append(file)\n",
    "        if file[:5] == 'train':\n",
    "            train.append(file)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "zipFilePath = \"../chess boards.zip\"\n",
    "\n",
    "trainPaths, testPaths = getFilePaths(zipFilePath)\n",
    "print(\"Files in test: \", len(trainPaths))\n",
    "print(\"Files in train: \", len(testPaths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "1890\n"
     ]
    }
   ],
   "source": [
    "# Parallel Loads Board Images for Training Purposes\n",
    "def HogTransform(img):\n",
    "    first_image_gray = color.rgb2gray(img)\n",
    "\n",
    "    fd, hog_image = hog(\n",
    "        first_image_gray,\n",
    "        orientations=8,\n",
    "        pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(1, 1),\n",
    "        visualize=True,\n",
    "        block_norm='L2-Hys',\n",
    "        feature_vector=True\n",
    "    )\n",
    "\n",
    "    hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "    hog_image_uint8 = (hog_image_rescaled * 255).astype(np.uint8)\n",
    "    return hog_image_uint8\n",
    "\n",
    "def read_and_store_modified_chess_images():\n",
    "    return\n",
    "\n",
    "def fen_from_position(position, fen_string):\n",
    "    rows = position // 8\n",
    "    cols = position % 8\n",
    "\n",
    "    character = fen_string[rows * 8 + cols]\n",
    "\n",
    "    if character.isdigit():\n",
    "        return ' ' * int(character)\n",
    "    else:\n",
    "        return character\n",
    "\n",
    "def fen_from_filename(filename):\n",
    "    parts = filename.split('/')\n",
    "    fen_part = parts[-1].split('.')[0]\n",
    "\n",
    "    fen_string = ''.join([' ' * int(char) if char.isdigit() else char for char in fen_part])\n",
    "    fen_string = fen_string.replace('-', '')\n",
    "\n",
    "    return fen_string\n",
    "\n",
    "src = zipFilePath\n",
    "random.shuffle(trainPaths)\n",
    "\n",
    "print(\"Running...\")\n",
    "lock = mp.Lock()\n",
    "manager = mp.Manager()\n",
    "processorCores = 12\n",
    "#data_dict = manager.dict({'fenstring': [], 'data': []})\n",
    "data_dict = manager.list()\n",
    "with mp.Pool(processes=processorCores) as p:\n",
    "    args = [(fileName, src, fen_from_filename, fen_from_position, NUM_SPACES_PER_BOARD, data_dict) for fileName in trainPaths[:NUM_TRAINING_IMAGES]]\n",
    "    results = [0]\n",
    "    results = p.starmap(runt, args)\n",
    "\n",
    "# Access the shared dictionary\n",
    "print(len(data_dict))\n",
    "\n",
    "combined_results = {'fenstring': [], 'data': []}\n",
    "\n",
    "# Initialize lists to store all data and fenstring items\n",
    "all_data_items = []\n",
    "all_fenstring_items = []\n",
    "\n",
    "for result in data_dict:\n",
    "    # Extend all_data_items with result['data']\n",
    "    all_data_items.extend(result['data'])\n",
    "\n",
    "    # Extend all_fenstring_items with result['fenstring']\n",
    "    all_fenstring_items.extend(result['fenstring'])\n",
    "\n",
    "# Assign the combined lists to combined_results\n",
    "combined_results['data'] = all_data_items\n",
    "combined_results['fenstring'] = all_fenstring_items\n",
    "\n",
    "joblib.dump(combined_results, PICKLE_PATH)\n",
    "read_and_store_modified_chess_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n",
      "(60000, 28, 28)\n",
      "60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 12:54:51.802143: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 12:54:52.063612: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 12:54:52.063764: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 12:54:52.066008: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 12:54:52.066139: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 12:54:52.066200: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 12:54:52.383301: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 12:54:52.383625: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 12:54:52.383656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-06 12:54:52.383791: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-06 12:54:52.384896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1715014494.805857    6708 service.cc:145] XLA service 0x7f4538005c70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1715014494.805980    6708 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2070 with Max-Q Design, Compute Capability 7.5\n",
      "2024-05-06 12:54:54.874381: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-06 12:54:55.138928: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  42/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.4772 - loss: 1.4314"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1715014496.309342    6708 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.7852 - loss: 0.5951\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8640 - loss: 0.3718\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8760 - loss: 0.3332\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8868 - loss: 0.3072\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8923 - loss: 0.2870\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9003 - loss: 0.2685\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9026 - loss: 0.2566\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9082 - loss: 0.2424\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9105 - loss: 0.2346\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2262\n",
      "313/313 - 2s - 5ms/step - accuracy: 0.8830 - loss: 0.3417\n",
      "\n",
      "Test accuracy: 0.8830000162124634\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "\n",
    "# shows a list of gpu devices recognized by tensorflow\n",
    "#print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "\n",
    "import os\n",
    "\"\"\"\n",
    "0 = all messages are logged (default behavior)\n",
    "1 = INFO messages are not printed\n",
    "2 = INFO and WARNING messages are not printed\n",
    "3 = INFO, WARNING, and ERROR messages are not printed \"\"\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# download fashion mnist dataset and split into train and test sets\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# create a list of the labels from the data\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "# shows the number of images and their resolution and num of training labels\n",
    "print(train_images.shape)\n",
    "print(len(train_labels))\n",
    "\n",
    "# scale images between 0 to 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "\n",
    "# show the first 25 images and their labels in training set\n",
    "#plt.figure(figsize=(10,10))\n",
    "#for i in range(25):\n",
    "    #plt.subplot(5,5,i+1)\n",
    "    #plt.xticks([])\n",
    "    #plt.yticks([])\n",
    "    #plt.grid(False)\n",
    "    #plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    #plt.xlabel(class_names[train_labels[i]])\n",
    "#plt.show()\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(28,28)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(784, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(500, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(500, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
